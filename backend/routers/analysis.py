"""
Endpoints de an√°lise de CV (lite, free, premium-paid, generate-pdf/word, status).
"""
from __future__ import annotations

import io
import logging
from datetime import datetime
from typing import Any

import sentry_sdk
from fastapi import APIRouter, File, Form, UploadFile, Request, BackgroundTasks, Response
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel

from dependencies import (
    supabase_admin,
    DEV_MODE,
    validate_user_id,
    _entitlements_status,
    _consume_one_credit,
    settings,
    IS_DEV,
)
from logic import analyze_preview_lite, extrair_texto_pdf, gerar_pdf_candidato, gerar_word_candidato
from mock_data import MOCK_PREVIEW_DATA, MOCK_PREMIUM_DATA

from slowapi import Limiter
from slowapi.util import get_remote_address

logger = logging.getLogger(__name__)

limiter = Limiter(key_func=get_remote_address)

router = APIRouter(prefix="/api", tags=["analysis"])


@router.get("/analysis/status/{session_id}")
def get_analysis_status(session_id: str) -> JSONResponse:
    """Endpoint para polling do status da an√°lise com progressive loading."""
    sentry_sdk.set_tag("endpoint", "get_analysis_status")
    
    if not supabase_admin:
        return JSONResponse(
            status_code=500,
            content={"error": "Supabase n√£o configurado. Defina SUPABASE_URL e SUPABASE_SERVICE_ROLE_KEY."},
        )
    
    try:
        response = supabase_admin.table("analysis_sessions").select(
            "status, current_step, result_data, created_at, updated_at"
        ).eq("id", session_id).limit(1).execute()
        
        if not response.data:
            return JSONResponse(
                status_code=404,
                content={"error": "Sess√£o n√£o encontrada."}
            )
        
        session = response.data[0]
        
        return JSONResponse(content={
            "session_id": session_id,
            "status": session["status"],
            "current_step": session["current_step"],
            "result_data": session["result_data"],
            "created_at": session["created_at"],
            "updated_at": session["updated_at"]
        })
        
    except Exception as e:
        sentry_sdk.capture_exception(e)
        return JSONResponse(status_code=500, content={"error": f"{type(e).__name__}: {e}"})


@router.post("/analyze-lite")
@limiter.limit("5/minute")
def analyze_lite(request: Request, file: UploadFile = File(...), job_description: str = Form(...), area_of_interest: str = Form("")) -> JSONResponse:
    try:
        sentry_sdk.set_tag("endpoint", "analyze_lite")
        
        file_bytes = file.file.read()
        from storage_manager import storage_manager
        storage_manager.save_temp_files(file_bytes, job_description)
        
        if DEV_MODE:
            print("üîß [DEV MODE] Retornando mock de an√°lise lite (sem processar IA)")
            return JSONResponse(content=MOCK_PREVIEW_DATA)
        
        cv_text = extrair_texto_pdf(io.BytesIO(file_bytes))

        # Determinismo: mesmo CV + mesma vaga + mesma √°rea retorna o mesmo resultado (cache de preview)
        from cache_manager import CacheManager
        cache_manager = CacheManager()
        cache_job_key = f"{job_description.strip()}\n[AREA]{(area_of_interest or '').strip().lower()}"
        preview_hash = cache_manager.generate_input_hash(cv_text, cache_job_key, model_version="preview-lite-v1")
        cached_preview = cache_manager.check_cache(preview_hash)
        if cached_preview:
            return JSONResponse(content=cached_preview)
        
        if area_of_interest:
            data = analyze_preview_lite(cv_text, job_description, forced_area=area_of_interest)
        else:
            data = analyze_preview_lite(cv_text, job_description)

        cache_manager.save_to_cache(
            input_hash=preview_hash,
            user_id=None,
            cv_text=cv_text,
            job_description=cache_job_key,
            result_json=data,
            model_version="preview-lite-v1",
            original_filename=file.filename if file and file.filename else None,
        )
        
        return JSONResponse(content=data)
    except Exception as e:
        sentry_sdk.capture_exception(e)
        return JSONResponse(status_code=500, content={"error": f"{type(e).__name__}: {e}"})


@router.post("/analyze-free")
@limiter.limit("5/minute")
def analyze_free(
    request: Request,
    file: UploadFile = File(...), 
    job_description: str = Form(...),
    area_of_interest: str = Form(""),
    user_id: str = Form(None)
) -> JSONResponse:
    """
    An√°lise gratuita (primeira an√°lise sem paywall).
    Retorna diagn√≥stico b√°sico com problemas identificados e 2 sugest√µes.
    """
    if user_id:
        sentry_sdk.set_context("user", {"id": user_id})
    sentry_sdk.set_tag("endpoint", "analyze_free")
    
    if user_id and not validate_user_id(user_id):
        return JSONResponse(
            status_code=400, 
            content={"error": "user_id inv√°lido. Deve ser um UUID v√°lido."}
        )
    
    try:
        file_bytes = file.file.read()
        from storage_manager import storage_manager
        storage_manager.save_temp_files(file_bytes, job_description, user_id)
        
        # Verifica se usu√°rio j√° usou an√°lise gratuita (se tiver user_id)
        if user_id and supabase_admin:
            try:
                usage = supabase_admin.table("free_usage").select("used_at").eq("user_id", user_id).limit(1).execute()
                if usage.data:
                    return JSONResponse(
                        status_code=403, 
                        content={"error": "Voc√™ j√° usou sua an√°lise gratuita. Fa√ßa upgrade para continuar."}
                    )
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao verificar uso gratuito: {e}")
        
        if DEV_MODE:
            print("üîß [DEV MODE] Retornando mock de an√°lise gratuita (sem processar IA)")
            limited_data = MOCK_PREVIEW_DATA.copy()
            return JSONResponse(content=limited_data)
        
        cv_text = extrair_texto_pdf(io.BytesIO(file_bytes))

        # Determinismo: mesmo CV + mesma vaga + mesma √°rea retorna o mesmo resultado (cache de preview)
        from cache_manager import CacheManager
        cache_manager = CacheManager()
        cache_job_key = f"{job_description.strip()}\n[AREA]{(area_of_interest or '').strip().lower()}"
        preview_hash = cache_manager.generate_input_hash(cv_text, cache_job_key, model_version="preview-lite-v1")
        cached_preview = cache_manager.check_cache(preview_hash)
        if cached_preview:
            return JSONResponse(content=cached_preview)
        
        if area_of_interest:
            data = analyze_preview_lite(cv_text, job_description, forced_area=area_of_interest)
        else:
            data = analyze_preview_lite(cv_text, job_description)

        cache_manager.save_to_cache(
            input_hash=preview_hash,
            user_id=user_id,
            cv_text=cv_text,
            job_description=cache_job_key,
            result_json=data,
            model_version="preview-lite-v1",
            original_filename=file.filename if file and file.filename else None,
        )
        
        # Registra uso gratuito
        if user_id and supabase_admin:
            try:
                supabase_admin.table("free_usage").insert({
                    "user_id": user_id,
                    "used_at": datetime.now().isoformat()
                }).execute()
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao registrar uso gratuito: {e}")
        
        return JSONResponse(content=data)
    except Exception as e:
        sentry_sdk.capture_exception(e)
        return JSONResponse(status_code=500, content={"error": f"{type(e).__name__}: {e}"})


class GeneratePdfRequest(BaseModel):
    data: dict[str, Any]
    user_id: str | None = None


@router.post("/generate-pdf")
def generate_pdf(request: GeneratePdfRequest) -> Response:
    try:
        pdf_bytes = gerar_pdf_candidato(request.data)
        
        if not pdf_bytes or len(pdf_bytes) == 0:
            return JSONResponse(
                status_code=500,
                content={"error": "Falha ao gerar PDF: arquivo vazio"}
            )
        
        if len(pdf_bytes) < 1024:
            return JSONResponse(
                status_code=500,
                content={"error": f"PDF gerado √© muito pequeno ({len(pdf_bytes)} bytes)"}
            )
        
        if not pdf_bytes.startswith(b'%PDF'):
            return JSONResponse(
                status_code=500,
                content={"error": "PDF gerado √© inv√°lido: cabe√ßalho ausente"}
            )
        
        return StreamingResponse(
            io.BytesIO(pdf_bytes),
            media_type="application/pdf",
            headers={
                "Content-Disposition": "attachment; filename=Curriculo_VANT.pdf",
                "Content-Length": str(len(pdf_bytes))
            }
        )
        
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": f"{type(e).__name__}: {e}"})


class GenerateWordRequest(BaseModel):
    data: dict[str, Any]
    user_id: str | None = None


@router.post("/generate-word")
def generate_word(request: GenerateWordRequest) -> Response:
    try:
        word_bytes_io = gerar_word_candidato(request.data)
        
        if not word_bytes_io:
            return JSONResponse(
                status_code=500,
                content={"error": "Falha ao gerar Word: arquivo nulo"}
            )
        
        word_bytes_io.seek(0)
        word_bytes = word_bytes_io.read()
        
        if not word_bytes or len(word_bytes) == 0:
            return JSONResponse(
                status_code=500,
                content={"error": "Falha ao gerar Word: arquivo vazio"}
            )
        
        if len(word_bytes) < 2048:
            return JSONResponse(
                status_code=500,
                content={"error": f"Word gerado √© muito pequeno ({len(word_bytes)} bytes)"}
            )
        
        if not word_bytes.startswith(b'PK'):
            return JSONResponse(
                status_code=500,
                content={"error": "Word gerado √© inv√°lido: n√£o √© um formato DOCX v√°lido"}
            )
        
        word_bytes_io.seek(0)
        
        return StreamingResponse(
            word_bytes_io,
            media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            headers={
                "Content-Disposition": "attachment; filename=Curriculo_VANT_Editavel.docx",
                "Content-Length": str(len(word_bytes))
            }
        )
        
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": f"{type(e).__name__}: {e}"})


@router.post("/analyze-premium-paid")
@limiter.limit("10/minute")
def analyze_premium_paid(
    request: Request,
    background_tasks: BackgroundTasks,
    user_id: str = Form(...),
    file: UploadFile | None = File(None),
    job_description: str = Form(...),
    cv_text: str = Form(""),
    area_of_interest: str = Form(""),
    competitor_files: list[UploadFile] | None = File(None),
) -> JSONResponse:
    sentry_sdk.set_context("user", {"id": user_id})
    sentry_sdk.set_tag("endpoint", "analyze_premium_paid")
    
    if not supabase_admin:
        return JSONResponse(
            status_code=500,
            content={"error": "Supabase n√£o configurado. Defina SUPABASE_URL e SUPABASE_SERVICE_ROLE_KEY."},
        )
    
    if user_id and not validate_user_id(user_id):
        return JSONResponse(
            status_code=400, 
            content={"error": "user_id inv√°lido. Deve ser um UUID v√°lido."}
        )
    
    try:
        # Se cv_text foi fornecido (reutiliza√ß√£o de CV), n√£o precisa de file
        file_bytes = None
        if file and file.filename:
            file_bytes = file.file.read()
            from storage_manager import storage_manager
            storage_manager.save_temp_files(file_bytes, job_description, user_id)
        elif not cv_text:
            return JSONResponse(status_code=400, content={"error": "Envie um arquivo PDF/DOCX ou forne√ßa cv_text."})
        
        # Verificar cr√©ditos (tanto em DEV quanto em produ√ß√£o)
        status = _entitlements_status(user_id)
        if not status.get("payment_verified") or int(status.get("credits_remaining") or 0) <= 0:
            return JSONResponse(status_code=400, content={"error": "Voc√™ n√£o tem cr√©ditos dispon√≠veis."})

        # Consumir cr√©dito
        _consume_one_credit(user_id)
        
        # Criar sess√£o de an√°lise para progressive loading
        import uuid
        session_id = str(uuid.uuid4())
        
        try:
            supabase_admin.table("analysis_sessions").insert({
                "id": session_id,
                "user_id": user_id,
                "status": "processing",
                "current_step": "starting",
                "result_data": {},
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat()
            }).execute()
            
            logger.info(f"‚úÖ Sess√£o de an√°lise criada: {session_id}")
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar sess√£o: {e}")
            return JSONResponse(status_code=500, content={"error": f"Erro ao criar sess√£o: {e}"})
        
        # Ler bytes dos competidores se existirem
        competitors_bytes = None
        if competitor_files:
            competitors_bytes = []
            for cf in competitor_files:
                cf_bytes = cf.file.read()
                if cf_bytes:
                    competitors_bytes.append(cf_bytes)
        
        # Modo DEV: retorna mock instantaneamente
        if DEV_MODE:
            print("üîß [DEV MODE] Retornando mock de an√°lise premium (sem processar IA)")
            
            supabase_admin.table("analysis_sessions").update({
                "status": "completed",
                "current_step": "completed",
                "result_data": MOCK_PREMIUM_DATA,
                "updated_at": datetime.now().isoformat()
            }).eq("id", session_id).execute()
            
            # Salvar no hist√≥rico (cached_analyses) para aparecer no Dashboard
            try:
                import hashlib
                from cache_manager import CacheManager
                cache_manager = CacheManager()
                input_hash = hashlib.sha256(
                    f"{job_description}{session_id}dev".encode()
                ).hexdigest()
                cache_manager.save_to_cache(
                    input_hash=input_hash,
                    user_id=user_id,
                    cv_text="[DEV MODE]",
                    job_description=job_description,
                    result_json=MOCK_PREMIUM_DATA
                )
                print("üíæ [DEV MODE] Mock salvo no hist√≥rico (cached_analyses)")
            except Exception as cache_err:
                print(f"‚ö†Ô∏è [DEV MODE] Erro ao salvar no hist√≥rico: {cache_err}")
            
            return JSONResponse(content={
                "session_id": session_id,
                "status": "completed",
                "message": "An√°lise mock conclu√≠da (DEV MODE)"
            })
        
        # Modo PRODU√á√ÉO: processar em background
        from dependencies import _process_analysis_background
        background_tasks.add_task(
            _process_analysis_background,
            session_id,
            user_id,
            file_bytes,
            job_description,
            area_of_interest,
            competitors_bytes,
            file.filename if file and file.filename else "cv_reused.pdf",
            cv_text if cv_text else None  # Texto pr√©-extra√≠do do CV
        )
        
        return JSONResponse(content={
            "session_id": session_id,
            "status": "processing",
            "message": "An√°lise iniciada. Use /api/analysis/status/{session_id} para acompanhar."
        })
        
    except Exception as e:
        sentry_sdk.capture_exception(e)
        return JSONResponse(status_code=500, content={"error": f"{type(e).__name__}: {e}"})
